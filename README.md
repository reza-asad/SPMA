# SPMA
This repository contains the code for Softmax Policy Mirror Ascent (SPMA), a policy optimization algorithm based on mirror ascent in the space of logits, using the log-sum-exp mirror map. The repository includes scripts to reproduce the [stable-baselines3](https://github.com/DLR-RM/stable-baselines3/tree/master) experiments from the AISTATS 2025 paper *Fast Convergence of Softmax Policy Mirror Ascent*.
